{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from math import *\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import functools\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from skimage.feature import hog\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "from lesson_functions import *\n",
    "np.random.seed(0xdeadbeef)\n",
    "\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook # Monkey patch\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "cars = glob.iglob('data/vehicles/**/*.png')\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "notcars = glob.iglob('data/non-vehicles/**/*.png')\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1000))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0xdeadbeef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('feature_selection', SelectFromModel(ExtraTreesClassifier())),\n",
    "                ('classification', LinearSVC(loss='hinge')),\n",
    "               ])\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy of classifier = ', round(clf.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My classifier predicts: ', clf.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def make_hardneg(out_path, neg=True):\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    if neg:\n",
    "        notcars = glob.glob('data/non-vehicles/**/*.png')\n",
    "    else:\n",
    "        cars = glob.glob('data/vehicles/**/*.png')\n",
    "    offset = len(car_features)\n",
    "\n",
    "    # Wrong indices\n",
    "    wrong = np.nonzero(y_pred != y)[0]\n",
    "    for w in wrong:\n",
    "        # False positives\n",
    "        if neg and y_pred[w] == 1 and y[w] == 0:\n",
    "            fname = notcars[w - offset]\n",
    "            copyfile(fname, out_path+'/hardneg_'+str(w - offset)+'.png')\n",
    "        elif not neg and y_pred[w] == 0 and y[w] == 1:\n",
    "            fname = cars[w]\n",
    "            copyfile(fname, out_path+'/hardpos_'+str(w)+'.png')\n",
    "\n",
    "# make_hardneg('data/hardpos/', False)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(X)\n",
    "conf = confusion_matrix(y, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "config = dict(color_space=color_space, \n",
    "            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "            orient=orient, pix_per_cell=pix_per_cell, \n",
    "            cell_per_block=cell_per_block, \n",
    "            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "joblib.dump({'model':clf, 'config':config}, 'models/clf_9727.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hog_feat': True, 'color_space': 'YUV', 'hist_bins': 16, 'orient': 9, 'hog_channel': 0, 'pix_per_cell': 8, 'hist_feat': True, 'spatial_feat': True, 'cell_per_block': 2, 'spatial_size': (16, 16)}\n"
     ]
    }
   ],
   "source": [
    "data = joblib.load('models/clf_9885_newhog.pkl')\n",
    "# data = joblib.load('models/clf_9869.pkl')\n",
    "# svc = data['model']\n",
    "clf = data['model']\n",
    "config = data['config']\n",
    "\n",
    "color_space = config['color_space']\n",
    "spatial_size = config['spatial_size']\n",
    "hist_bins = config['hist_bins']\n",
    "orient = config['orient']\n",
    "pix_per_cell = config['pix_per_cell']\n",
    "cell_per_block = config['cell_per_block']\n",
    "hog_channel = config['hog_channel']\n",
    "spatial_feat = config['spatial_feat']\n",
    "hist_feat = config['hist_feat']\n",
    "hog_feat = config['hog_feat']\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_windows(img, windows, clf, color_space='RGB',\n",
    "                    spatial_size=None, hist_bins=32,\n",
    "                    hist_range=(0, 256), orient=9,\n",
    "                    pix_per_cell=8, cell_per_block=2,\n",
    "                    hog_channel=0, spatial_feat=True,\n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    if spatial_size is None:\n",
    "        spatial_size = (32, 32)\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    all_features = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space,\n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                            orient=orient, pix_per_cell=pix_per_cell,\n",
    "                            cell_per_block=cell_per_block,\n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = np.array(features).reshape(1, -1)\n",
    "\n",
    "        #6) Predict using your classifier\n",
    "        dec = clf.decision_function(test_features)\n",
    "        prediction = int(dec > 0.5)\n",
    "\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_windows(pyramid, image_size):\n",
    "    output = []\n",
    "    for w_size, y_lims in pyramid:\n",
    "        windows = slide_window(image_size, x_start_stop=[None, None], y_start_stop=y_lims, \n",
    "                        xy_window=w_size, xy_overlap=(0.5, 0.5))\n",
    "        output.append(windows)\n",
    "#         output.extend(windows)\n",
    "    return output\n",
    "\n",
    "def multiscale_detect(image, clf, config, windows, verbose=False):\n",
    "    \n",
    "    color_space = config['color_space']\n",
    "    spatial_size = config['spatial_size']\n",
    "    hist_bins = config['hist_bins']\n",
    "    orient = config['orient']\n",
    "    pix_per_cell = config['pix_per_cell']\n",
    "    cell_per_block = config['cell_per_block']\n",
    "    hog_channel = config['hog_channel']\n",
    "    spatial_feat = config['spatial_feat']\n",
    "    hist_feat = config['hist_feat']\n",
    "    hog_feat = config['hog_feat']\n",
    "    \n",
    "    candidates = search_windows(image, windows, clf, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def update_heatmap(candidates, image_shape, heatmap = None):\n",
    "    if heatmap is None:\n",
    "        heatmap = np.zeros((image_shape[0], image_shape[1]), np.uint8)\n",
    "\n",
    "    for pt1, pt2 in candidates:\n",
    "#     for x1, y1, x2, y2 in candidates:\n",
    "        x1, y1 = pt1\n",
    "        x2, y2 = pt2\n",
    "        x1 = min(max(x1, 0), image_shape[1])\n",
    "        x2 = min(max(x2, 0), image_shape[1])\n",
    "        y1 = min(max(y1, 0), image_shape[0])\n",
    "        y2 = min(max(y2, 0), image_shape[0])\n",
    "        xv, yv = np.meshgrid(range(x1, x2), range(y1, y2))\n",
    "\n",
    "        heatmap[yv, xv] += 1\n",
    "\n",
    "#     cv2.GaussianBlur(heatmap, (31,31), 0, dst=heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def find_vehicles(heatmap):\n",
    "    # Detect clusters\n",
    "    labels = label(heatmap)\n",
    "\n",
    "    _, contours, _ = cv2.findContours(heatmap, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = [cv2.boundingRect(pts) for pts in contours]\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyramid = [((64, 64),  [400, 500]),\n",
    "           ((96, 96),  [400, 500]),\n",
    "           ((128, 128),[450, None]),\n",
    "           ((192, 192),[450, None]),\n",
    "#             ((256, 256),[450, None])\n",
    "      ]\n",
    "image_size = (720, 1280)\n",
    "windows = create_windows(pyramid, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Malisiewicz et al.\n",
    "# http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    " \n",
    "\t# if the bounding boxes integers, convert them to floats --\n",
    "\t# this is important since we'll be doing a bunch of divisions\n",
    "\tif boxes.dtype.kind == \"i\":\n",
    "\t\tboxes = boxes.astype(\"float\")\n",
    " \n",
    "\t# initialize the list of picked indexes\t\n",
    "\tpick = []\n",
    " \n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    " \n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    " \n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list and add the\n",
    "\t\t# index value to the list of picked indexes\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    " \n",
    "\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t# for the end of the bounding box\n",
    "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    " \n",
    "\t\t# compute the width and height of the bounding box\n",
    "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
    "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "\t\t# compute the ratio of overlap\n",
    "\t\toverlap = (w * h) / area[idxs[:last]]\n",
    " \n",
    "\t\t# delete all indexes from the index list that have\n",
    "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "\treturn boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from filters import kalman_predict, kalman_measure\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import functools\n",
    "import collections\n",
    "\n",
    "def bbox_overlap(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "#         area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    area = (x4 - x3 + 1) * (y4 - y3 + 1)\n",
    "\n",
    "    xx1 = np.maximum(x1, x3)\n",
    "    yy1 = np.maximum(y1, y3)\n",
    "    xx2 = np.minimum(x2, x4)\n",
    "    yy2 = np.minimum(y2, y4)\n",
    "\n",
    "    # compute the width and height of the bounding box\n",
    "    w = np.maximum(0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "    # compute the ratio of overlap\n",
    "    overlap = (w * h) / area\n",
    "    return overlap\n",
    "\n",
    "    \n",
    "def centroid(box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    return ((x1+x2)/2., (y1+y2)/2.)\n",
    "    \n",
    "class VehicleTracker(object):\n",
    "    \"\"\"\n",
    "    Tracks vehicle candidates using a Kalman filter\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, process_noise = 5.0, measurement_noise = 20.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        img_size : tuple\n",
    "            The shape of the video frame\n",
    "            \n",
    "        process_noise : float\n",
    "            Process noise for kalman filter [pixels^2]\n",
    "        \n",
    "        measurement_noise : float\n",
    "            Measurement covariance in x and y directions [pixels^2]\n",
    "        \"\"\"\n",
    "        self.img_size = img_size\n",
    "        self.H = np.array([[1., 0., 0., 0., 0., 0.],\n",
    "                           [0., 1., 0., 0., 0., 0.]])\n",
    "        self.R = np.eye(2)*measurement_noise\n",
    "        \n",
    "        self.Q = np.eye(6)*process_noise\n",
    "        self.F = np.array([[0., 0., 1., 0., 0., 0.],\n",
    "                           [0., 0., 0., 1., 0., 0.],\n",
    "                           [0., 0., 0., 0., 1., 0.],\n",
    "                           [0., 0., 0., 0., 0., 1.],\n",
    "                           [0., 0., 0., 0., 0., 0.],\n",
    "                           [0., 0., 0., 0., 0., 0.]])\n",
    "        \n",
    "        self.P0 = np.eye(6)*4000.0  # Initial covariance of any new candidate\n",
    "        self.predict = functools.partial(kalman_predict, F = self.F, Q = self.Q)\n",
    "        self.measure = functools.partial(kalman_measure, H = self.H, R = self.R)\n",
    "    \n",
    "        self.candidates = []\n",
    "    \n",
    "    def create_candidate(self, meas):\n",
    "        \"\"\"\n",
    "        Creates a new tracking candidate from a measurement (bounding box)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        meas - tuple\n",
    "            tuple of 4 numbers denoting the top-left and bottom-right corners of the box\n",
    "        \"\"\"\n",
    "        # Position\n",
    "        x = list(centroid(meas))\n",
    "        # Velocity\n",
    "        x.append(-0.1 if x[0] > self.img_size[1]/2 else 0.1)\n",
    "        # Acceleration\n",
    "        x.append(-0.1)\n",
    "        x.extend([0.001, 0.001])\n",
    "        \n",
    "        return {'bbox': np.array(meas).astype(np.int32), 'x': np.array(x), 'P': np.copy(self.P0), 'age': 0}\n",
    "        \n",
    "    def detect(self, measurements):\n",
    "        \"\"\"\n",
    "        Uses measurements from OpenCV detect vehicles in the video stream\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        measurements : list\n",
    "            List of bounding boxes detected by the classifier (and heatmap)\n",
    "        \"\"\"\n",
    "        obox_ul = np.array([(0.1*self.img_size[1], 0.1*self.img_size[0])])\n",
    "        obox_br = np.array([(0.9*self.img_size[1], 0.9*self.img_size[0])])\n",
    "        \n",
    "        meas_centroid = [centroid(meas) for meas in measurements]\n",
    "        if len(self.candidates) == 0:\n",
    "            nonmax_meas = non_max_suppression_fast(np.array(measurements), overlapThresh=0.2)\n",
    "            self.candidates = [self.create_candidate(meas) for meas in nonmax_meas]\n",
    "        else:\n",
    "            # Assign measurements to candidates based on overlap\n",
    "            cand_measurements = collections.defaultdict(list)\n",
    "            for j, (meas, cent) in enumerate(zip(measurements, meas_centroid)):\n",
    "                # Overlap with each candidate\n",
    "                overlap = [bbox_overlap(cand['bbox'], meas) for cand in self.candidates]\n",
    "                # Distance to each candidate\n",
    "                distance = [np.linalg.norm(cand['x'][:2] - cent) for cand in self.candidates]\n",
    "                \n",
    "                max_cand_idx = np.argmax(overlap)\n",
    "                min_dist_idx = np.argmin(distance)\n",
    "                \n",
    "                if overlap[max_cand_idx] < 0.1 and distance[max_cand_idx] > 50:\n",
    "                    self.candidates.append(self.create_candidate(meas))\n",
    "                else:\n",
    "                    # Assign measurement to candidate\n",
    "                    if overlap[max_cand_idx] >= 0.1:\n",
    "                        cand_measurements[max_cand_idx].append(meas)\n",
    "                    else:\n",
    "                        cand_measurements[min_dist_idx].append(meas)\n",
    "            for i, cand in enumerate(self.candidates):\n",
    "                meas_list = cand_measurements[i]\n",
    "                x1, P1 = self.predict(cand['x'], cand['P'])\n",
    "                for meas in meas_list:\n",
    "                    x1, P1 = self.measure(z = centroid(meas), x = x1, P = P1)\n",
    "\n",
    "                # Increment age if no measurements matched this candidate\n",
    "                if not meas_list:\n",
    "                    self.candidates[i]['age'] = cand['age'] + 1\n",
    "                else:\n",
    "                    self.candidates[i]['age'] = cand['age'] - 1\n",
    "                    \n",
    "                    old_bbox = cand['bbox']\n",
    "                    bbox_list = np.array(meas_list)# + [cand['bbox']])\n",
    "                    w_list, h_list = bbox_list[:,2] - bbox_list[:,0], bbox_list[:,3] - bbox_list[:,1]\n",
    "                    w, h = np.average(w_list), np.average(h_list)\n",
    "                \n",
    "                    new_bbox = np.array(((x1[0] - w/2), (x1[1] - h/2), \n",
    "                                         (x1[0] + w/2), (x1[1] + h/2)))\n",
    "                    self.candidates[i]['bbox'] = (0.05*new_bbox + 0.95*cand['bbox']).astype(np.int32)\n",
    "                    \n",
    "                self.candidates[i]['x'] = x1\n",
    "                self.candidates[i]['P'] = P1\n",
    "            \n",
    "            self.cleanup()\n",
    "\n",
    "    def cleanup(self, max_age=40):\n",
    "        \"\"\"\n",
    "        Deletes any candidates older than max_age\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_age : int\n",
    "            Maximum age of candidate before which it is deleted\n",
    "        \"\"\"\n",
    "        cand_1 = [c for c in self.candidates if c['age'] <= max_age]\n",
    "        self.candidates = cand_1\n",
    "    \n",
    "    def draw_bboxes(self, image):\n",
    "        for c in self.candidates:\n",
    "            bbox = c['bbox']\n",
    "            if np.trace(c['P']) > 100:\n",
    "                continue\n",
    "#             cv2.putText(image, 'P :'+str(c['P']), centroid(bbox), cv2.FONT_HERSHEY_SIMPLEX, 4, (0,0,0),2,cv2.LINE_AA)\n",
    "            if c['age'] < -10:\n",
    "                cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0,255,0), 6)\n",
    "            elif c['age'] < 0:\n",
    "                cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0,0,255), 3)\n",
    "\n",
    "        return image\n",
    "\n",
    "tracker = VehicleTracker((720, 1280))\n",
    "meas1 = [(864, 432, 928, 496), (816, 400, 912, 496), (1152, 400, 1248, 496)]\n",
    "meas2 = [(874, 432, 918, 496), (826, 400, 912, 456), (1122, 400, 1238, 496)]\n",
    "tracker.detect(meas1)\n",
    "tracker.detect(meas2)\n",
    "print(len(tracker.candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def process_image(image, params):\n",
    "    config, clf, all_windows = params['clf_config'], params['clf'], params['windows']\n",
    "\n",
    "    if params['cache_enabled']:\n",
    "        cache = process_image.cache\n",
    "        if cache['heatmaps'] is None:\n",
    "            cache['heatmaps'] = collections.deque(maxlen=params['heatmap_cache_length'])\n",
    "        \n",
    "        if 'tracker' not in cache:\n",
    "            cache['tracker'] = VehicleTracker(image.shape)\n",
    "        frame_ctr = cache['frame_ctr']\n",
    "        tracker = cache['tracker']\n",
    "        cache['frame_ctr'] += 1\n",
    "\n",
    "        extra = [(c['bbox'][:2], c['bbox'][2:]) for c in tracker.candidates]\n",
    "        windows = all_windows[frame_ctr % len(all_windows)] + extra\n",
    "#         windows = itertools.chain(*all_windows)\n",
    "    else:\n",
    "        windows = itertools.chain(*all_windows)\n",
    "\n",
    "    measurements = multiscale_detect(image, clf, config, windows)\n",
    "#     current_heatmap = update_heatmap(measurements, image.shape)\n",
    "    if params['cache_enabled']:\n",
    "        pass\n",
    "#         current_heatmap = update_heatmap(measurements, image.shape)\n",
    "#         cache['heatmaps'].append(current_heatmap)\n",
    "#         thresh_heatmap = sum(cache['heatmaps'])\n",
    "    else:\n",
    "        current_heatmap = update_heatmap(measurements, image.shape)\n",
    "        thresh_heatmap = current_heatmap\n",
    "\n",
    "    if params['cache_enabled']:\n",
    "#         Z = [tuple(itertools.chain(*b)) for b in measurements]\n",
    "        Z = []\n",
    "        current_heatmap = update_heatmap(measurements, image.shape)\n",
    "        cache['heatmaps'].append(current_heatmap)\n",
    "        thresh_heatmap = sum(cache['heatmaps'])\n",
    "\n",
    "        thresh_heatmap[thresh_heatmap < params['heatmap_threshold']] = 0\n",
    "        cv2.GaussianBlur(thresh_heatmap, (31,31), 0, dst=thresh_heatmap)\n",
    "\n",
    "        labels = label(thresh_heatmap)\n",
    "\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            bbox = (np.min(nonzerox), np.min(nonzeroy), np.max(nonzerox), np.max(nonzeroy))\n",
    "            Z.append(bbox)\n",
    "            \n",
    "        tracker.detect(Z)\n",
    "        im2 = tracker.draw_bboxes(np.copy(image))\n",
    "    else:\n",
    "        thresh_heatmap[thresh_heatmap < params['heatmap_threshold']] = 0\n",
    "        cv2.GaussianBlur(thresh_heatmap, (31,31), 0, dst=thresh_heatmap)\n",
    "\n",
    "        labels = label(thresh_heatmap)\n",
    "\n",
    "\n",
    "        im2 = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    return im2\n",
    "\n",
    "def clear_cache():\n",
    "    process_image.cache = {\n",
    "        'last_heatmap': None,\n",
    "        'heatmaps': None,\n",
    "        'frame_ctr': 0\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "params = {}\n",
    "params['clf_config'] = config\n",
    "params['clf'] = clf\n",
    "params['windows'] = windows\n",
    "params['cache_enabled'] = True\n",
    "params['heatmap_cache_length'] = 10\n",
    "params['heatmap_threshold'] = 1\n",
    "\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "im2 = process_image(image, params)\n",
    "plt.imshow(im2)\n",
    "# test_images = glob.glob('test_images/*.jpg')\n",
    "# for fname in test_images:\n",
    "#     im = mpimg.imread(fname)\n",
    "#     im2 = process_image(im, params)\n",
    "#     mpimg.imsave('output_images/'+os.path.basename(fname), im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "params = {}\n",
    "params['clf_config'] = config\n",
    "params['clf'] = clf\n",
    "params['windows'] = windows\n",
    "params['cache_enabled'] = True\n",
    "params['heatmap_cache_length'] = 25\n",
    "params['heatmap_threshold'] = 5\n",
    "\n",
    "vid_output = 'test_video_out.mp4'\n",
    "clip = VideoFileClip('test_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_video_out.mp4\n",
      "[MoviePy] Writing video test_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 38/39 [00:04<00:00,  7.67it/s]      | 2/39 [00:00<00:03, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_out.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vid_clip = clip.fl_image(lambda x: process_image(x, params))\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "params = {}\n",
    "params['clf_config'] = config\n",
    "params['clf'] = clf\n",
    "params['windows'] = windows\n",
    "params['cache_enabled'] = True\n",
    "params['heatmap_cache_length'] = 25\n",
    "params['heatmap_threshold'] = 5\n",
    "\n",
    "vid_output = 'project_short_out.mp4'\n",
    "clip = VideoFileClip('project_short.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_short_out.mp4\n",
      "[MoviePy] Writing video project_short_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/201 [00:11<00:17,  6.72it/s]      | 1/201 [00:00<00:31,  6.45it/s]"
     ]
    }
   ],
   "source": [
    "vid_clip = clip.fl_image(lambda x: process_image(x, params))\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "params = {}\n",
    "params['clf_config'] = config\n",
    "params['clf'] = clf\n",
    "params['windows'] = windows\n",
    "params['cache_enabled'] = True\n",
    "params['heatmap_cache_length'] = 25\n",
    "params['heatmap_threshold'] = 5\n",
    "\n",
    "vid_output = 'project_video_out.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vid_clip = clip.fl_image(lambda x: process_image(x, params))\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(len(process_image.cache['tracker'].candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
